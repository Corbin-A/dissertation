\section{Introduction}\label{intro}

Article headlines play an increasingly important role in today's information-dense world. Their intent is to be a highly digestible summary of the information contained within the associated article so the reader can decide whether the content will be of interest. But they also need to hook the reader in and grab their attention. In the days of newspaper media, this may have only applied to front-page headlines, enticing a potential reader to buy the paper. In the age of online journalism, however, every article is an opportunity to generate revenue by having readers visit their site. Setting aside the 24-hour news cycle from any one particular publication, resources like Reddit, Twitter and Facebook enable and indeed profit from their users seeing dozens if not hundreds of headlines every day.

This becomes a problem when people start are so inundated with information that they propagate headlines uninformed of the contents within. Take, for instance, a recent report that uncovered that 59\% of articles on Twitter were never clicked or read before being shared~\cite{Gabielkov2016}. Even for issues that an individual deems important, the headline is often the only exposure to the information that said person has had. Headlines can also cause substantive misconceptions for those who do not read the article as well~\cite{Wenzlaff1981}.

Furthermore, in the case of misleading headlines, evidence has shown that, even for individuals that read the associated articles, biases are created from the first impressions that headlines form~\cite{Ecker2014}. Even if the misleading element(s) of the headline is addressed within the article, the reader is still more likely to be misinformed after fully reading the article content~\cite{Ecker2014}. The first impressions that headlines provide are nearly impossible to overcome. It truly is difficult to overstate their importance.

Suffice it to say, headlines play a crucial role in our daily digestion of information and deserve the attention of the Natural Language Processing (NLP) community. Unfortunately, we are still many years away from being able to tackle some of the more pressing concerns revolving around headlines and their effect on the public. We are currently still in the early stages of generating headlines from article content, but this means that there are many interesting questions to explore.

Therefore, this research project hopes to contribute to the field of abstractive text summarization (Sec.~\ref{textsum}) by exploring one of the open questions. Current undertakings within this area of interest have used attentional sequence-to-sequence models (seq2seq; Sec.~ref{seq2seq}), a type of Recurrent Neural Network (RNN; Sec.~\ref{rnn}) to achieve the best results thus far. But teacher forcing (Sec.~\ref{tf}), a method used to help train seq2seq models, has not been explored in great depth, nor have the capabilities been realized until recently. Therefore, this project focuses on studying the effects of various teacher forcing techniques for the task of headline summarization, in an attempt to help guide the direction of future seq2seq research.